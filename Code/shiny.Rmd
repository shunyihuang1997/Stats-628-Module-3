---
title: "Untitled"
output: html_document
date: "2022-11-17"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r}
library(shiny)
library(shinyvalidate)
library(shinyjs)
library(tidyverse)
library(WVPlots)
library(rsconnect)
library(reticulate)
library(wordcloud2)
library(wordcloud)
library(RColorBrewer)
# py_pack = c('pandas', 'numpy','matplotlib','collections','plotly','tqdm','seaborn','nltk')
# for (pack in py_pack){
#   py_install(pack)
# }

#py_install("pandas")
#source_python("./app.py")
#use_condaenv("base")

CA_Asian_business_review = read.csv('CA_Asian_business_review.csv')
```


```{python}
import pandas as pd
import matplotlib.pyplot as plt
import collections
from sklearn import preprocessing
import plotly.io as pio
import sys
import warnings
warnings.filterwarnings('ignore')

import numpy as np
from tqdm import tqdm
import chardet
from collections import Counter
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px

from nltk.stem import WordNetLemmatizer
import nltk
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from wordcloud import WordCloud
import textblob
from collections import defaultdict
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import re
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import math
from nltk import bigrams,trigrams,ngrams
from collections import Counter
from sklearn.metrics import confusion_matrix
from nltk import everygrams, word_tokenize
from sklearn.model_selection import GridSearchCV
from sklearn.tree import DecisionTreeClassifier
from nltk.stem import WordNetLemmatizer
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import plot_confusion_matrix
CA_Asian_business_review = pd.read_csv('CA_Asian_business_review.csv',low_memory=False)
CA_Asian_business_review = CA_Asian_business_review[CA_Asian_business_review['is_open'] != 0].reset_index(drop = True)
```




```{python}
################## word cloud #########################
def show_word_cloud(sentiment, business_name):
  new_df= CA_Asian_business_review[CA_Asian_business_review['sentiment'] == sentiment].reset_index(drop=True)
  new_df= new_df[new_df['name'] == business_name].reset_index(drop=True)
  w_c = ""
  for i in range(len(new_df)):
    cur_list = new_df.loc[i,'text_cleaned'].split(',')
    for word in cur_list:
      word = word[2:-1]
      w_c += "".join(word)+ " "
  
  
  wordcloud_final = WordCloud(width = 800, height = 800, background_color ='white',min_font_size = 10, collocation_threshold = 3, min_word_length=3).generate(w_c)
  
  
  plt.imshow(wordcloud_final)
  plt.title(str(sentiment))
  plt.axis("off")
  plt.tight_layout(pad = 0)
  plt.show()
```




```{python}

def check_len(sentiment, business_name):
  new_df= CA_Asian_business_review[CA_Asian_business_review['sentiment'] == sentiment].reset_index(drop=True)
  new_df= new_df[new_df['name'] == business_name].reset_index(drop=True)
  cur_len = len(new_df)
  return cur_len


```







```{python}
######################## N-gram word frequency ##########################
def generate_N_grams(text,ngram):
  temp=zip(*[text[i:] for i in range(0,ngram)])
  ans=["".join(ngram) for ngram in temp]
  return ans


  #Plot top 15 negative ngram word
  def n_gram_plot(num_gram,business_name,num_result,sentiment, font, rotation):
    negative_dict = defaultdict(int)
    new_df = CA_Asian_business_review[CA_Asian_business_review.sentiment == sentiment]
    new_df = new_df[new_df.name == business_name]
    for text in new_df.text_cleaned:
      cur_list = text.split(",")
      for word in generate_N_grams(cur_list,num_gram):
        word = word.replace("'",'')
        negative_dict[word] += 1
            
            
    df_negative = pd.DataFrame(sorted(negative_dict.items(), key = lambda x : x[1], reverse= True))
    
  
    if sentiment == 'Positive':
      color = 'green'
    elif sentiment == 'Neutral':
      color = 'yellow'
    else:
      color = 'red'
  
    plt.figure(figsize=(6,2),dpi = 100)
    plt.bar(df_negative[0][:num_result], df_negative[1][:num_result], color = color, width = 0.3)
    plt.xticks(rotation = rotation)
    plt.ylabel("Count")
    plt.title("Top " + str(num_result) + ' '+ sentiment + " word")
    plt.xticks(fontsize = font)
    plt.yticks(fontsize = font)
    plt.show()

```






```{python}
#def parking_scatter():
has_parking = CA_Asian_business_review[CA_Asian_business_review['lot'] == True]
no_parking = CA_Asian_business_review[CA_Asian_business_review['lot'] == False]

color_scale = [(0, 'orange'), (1,'red')]
fig = px.scatter_mapbox(CA_Asian_business_review, 
                        lat="latitude", 
                        lon="longitude", 
                        hover_name="name", 
                        hover_data=["average_stars",'address'],
                        color="lot",
                        color_continuous_scale=color_scale,
                        size="average_stars",
                        zoom=8, 
                        height=800,
                        width=800)

fig.update_layout(mapbox_style="open-street-map")
fig.update_layout(margin={"r":0,"t":0,"l":0,"b":0})
fig.show()
  
pio.write_html(fig, file = 'parking.html', auto_open = True)
```


```{python}
#Generate food list
Chinese_food_list = ['Almond milk', 'Ants Climbing a Tree','Asian pear','Baby bok choy','Baijiu','Beef brisket',"Beggar's Chicken",'Bingtang hulu','Bitter melon','Bubble tea',
"Buddha's Delight","Cantonese roast duck",'Century egg', 'thousand-year egg','Cha siu', 'Cantonese roast pork','Char kway teow',
'Chicken feet','Chinese sausage','Chow mein','Chrysanthemum tea','Claypot rice','Congee','Conpoy (dried scallops)','Crab rangoon','Dan Dan noodles',
'Dragonfruit',"Dragon's Beard candy","Dried cuttlefish",'Drunken chicken','Dry-fried green beans','Egg drop soup','Egg rolls','Egg tart','Fresh bamboo shoots',
'Fortune cookies','Fried milk','Fried rice','Gai lan' ,"General Tso's Chicken",'Gobi Manchurian','Goji berries' ,'Grass jelly','Hainan chicken rice','Hand-pulled noodles','Har gau ',
'Haw flakes','Hibiscus tea','Hong Kong-style Milk Tea','Hot and sour soup','Hot Coca-Cola with Ginger','Hot Pot',
'Iron Goddess tea' ,'Tieguanyin','Jellyfish','Kosher Chinese food','Kung Pao Chicken','Lamb skewers', "yangrou chua'r","Lion's Head meatballs",
'Lomo Saltado','Longan fruit','Lychee','Macaroni in soup with Spam','Malatang','Mantou','Mapo Tofu','Mock meat',
'Mooncake', 'Nor mai gai','Pan-fried dumplings','Peking duck','Pineapple bun','Prawn crackers',"Pu'er tea",'Rambutan',
'Red bean','Red bayberry','Red cooked pork','Roast pigeon','Rose tea','Roujiamo','Scallion pancakes','Shaved ice dessert',
'Sesame chicken','Sichuan pepper','Sichuan preserved vegetable', 'zhacai','Silken tofu','Soy milk','Steamed egg custard','Stinky tofu','Sugar cane juice',
'Sweet and sour pork', 'Sweet and sour chicken','Sweet and sour shrimp','Taro','Tea eggs','Tea-smoked duck','Turnip cake (law bok gau)',
'Twice-cooked pork','Water chestnut cake', 'mati gau','Wonton noodle soup','Wood ear',
'Xiaolongbao,' 'soup dumplings','Yuanyang','Yunnan goat cheese']


Japanese_food_list = ['sushi', 'ramen', 'udon', 'matcha', 'sashimi', 'tempura', 'unagi', 'wagyu', 'kushiyaki', 'yakitori', 'takoyaki', 'tofu', 'miso', 'kaisendon', 'donburi', 'chirashizushi',
'eel', 'unagi', 'anago', 'zuke', 'tako tamago', 'fukagawa', 'fugu', 'crab', 'okonomiyaki', 'oysters', 'gyoza', 'karaage', 'Japanese curry', 'croquette', 'korokke', 'yakiniku', 'tonkatsu'
, 'miso katsu', 'motsunabe', 'jingisukan', 'basashi', 'sakuraniku', 'dashi', 'tebasaki', 'doteni', 'kishimen', 'tsukemen', 'kakuni manju', 'champon', 'chawanmushi', 'konnyaku', 'tamagoyaki',
'odon', 'nabemono', 'onigiri', 'monjayaki', 'okonomiyaki', 'TKG', 'yakiniku', 'kaiseki','mochi', 'castella', 'sake', 'shabu shabu', 'miso Soup', 'soba', 'gyudon', 'natto','kashipan', 'sukiyaki',
'mentaiko', 'nikujaga', 'edamame', 'yakisoba','wagashi']


Korean_food_list = ['bibimbap', 'gimbap', 'tteokguk', 'japchae', 'ramyun', 'naengmyeon', 'haemul pajeon', 'godeungo jorim', 'ganjang gejang', 'nakji bokkeum', 'hotteok', 'tteokbokki',
'kimchi', 'samgyetang', 'sundubu jjigae', 'gamjatang', 'budae jjigae', 'army stew', 'galbijjim', 'bulgogi', 'samgyeopsal','Korean fried chicken', 'bossam', 'soondae', 'bingsu', 'sikhye', 'banchan',
'maekju','chueotang', 'gogigui', 'Korean BBQ', 'gomtang', 'jajangmyeon', 'jjukumi', 'kalguksu', 'makgeolli', 'mandu', 'naengmyeon', 'gochujang', 'octopus', 'squid', 'nakji bokkeum', 'ojingeo bokkeum',
'jeon', 'haemul pajeon', 'sannakji', 'seolnongtang', 'beongdegi', 'bindaetteok', 'fishcake', 'eomuk', 'odeng', 'tteokbokki', 'gyeranppang', 'hotteok', 'soondae','twigim', 'tempura', 'ddongbbang',
'dondurma', 'schnee pang', 'tornado potato']

```




```{python}
#Plot for TFIDF score
new_Chinese_food_list = []
new_Japanese_food_list = []
new_Korean_food_list = []

def init_new_list (old_list, new_list):
  for word in old_list:
    cur_word = word.split(' ')
    for i in cur_word:
        new_list.append(i)

init_new_list(Chinese_food_list, new_Chinese_food_list)
init_new_list(Japanese_food_list, new_Japanese_food_list)
init_new_list(Korean_food_list, new_Korean_food_list)



def tfidf_viz(business_name, sentiment, num_gram, top_n, font, rotation, category):
  spec_restaurant = CA_Asian_business_review[CA_Asian_business_review['name'] == business_name]
  spec_sent = spec_restaurant[spec_restaurant['sentiment'] == sentiment]
  
  tfidf = TfidfVectorizer(ngram_range=(1,num_gram))
  spec_sent['TFIDF_text'] = [''.join(map(str,l)) for l in spec_sent.text_cleaned]
  transformed = tfidf.fit_transform(pd.Series(spec_sent.TFIDF_text))
  
  temp_df = pd.DataFrame(transformed[0].T.todense(),index=tfidf.get_feature_names(), columns=["TF-IDF"])
  
  temp_df = temp_df.sort_values('TF-IDF', ascending=False)
  
  temp_df = temp_df[temp_df['TF-IDF'] > 0].reset_index()
  temp_df = temp_df.rename(columns= {'index':'text'})
  
  if category ==  'Chinese':
    cur_list =new_Chinese_food_list
  elif category == 'Japanese':
    cur_list =new_Japanese_food_list
  elif category == 'Korean':
    cur_list =new_Korean_food_list
  else:
    cur_list = new_Chinese_food_list+new_Japanese_food_list+new_Korean_food_list
  
  
  index_list = []
  for i in range(len(temp_df)):
      word = temp_df.loc[i,'text']
      cur_word = word.split(' ')
      if not any(elem in elem in cur_list for elem in cur_word):
          index_list.append(i)
  
  temp_df.drop(index_list,axis = 0, inplace=True)
  
  
  temp_df = temp_df.head(top_n)
  temp_df.plot(x = 'text', y = 'TF-IDF', kind = 'bar')
  plt.xticks(rotation = rotation,fontsize = font)
  plt.ylabel('TF-IDF Score')
  plt.show()

```





```{r}
#Modeling
library(VGAM)
library(cdabookdb)
library(cdabookfunc)
library(tidyr)
library(stringr)
library(splitTools)
library(RColorBrewer)
data = read.csv("final_data.csv")

Y = data["comment_star"]
factorY = factor(c(t(Y)))
data$OrderStar = ordered(factorY,labels=c("1","2","3","4","5"))
col_list = c(colnames(data))
data[,c(1,6:16,18,19,20)] <- lapply(data[,c(1,6:16,18,19,20)], factor)


data_china=subset.data.frame(data, data$general_category == "Chinese" & data$Total_hour!=0)
data_jpn=subset.data.frame(data, data$general_category == "Japanese" & data$Total_hour!=0)
data_krn=subset.data.frame(data, data$general_category == "Korean" & data$Total_hour!=0)
data_AF=subset.data.frame(data, data$general_category == "Asian Fusion" & data$Total_hour!=0)

train.rows <- sample(rownames(data), dim(data)[1]*0.8)
general_train <- data[train.rows,]



train_test_split = function(df){
  train.rows <- sample(rownames(df), dim(df)[1]*0.8)
  train <- df[train.rows,]
  return(train)
}


CN_model  = vglm(OrderStar ~  BikeParking 
          + HasTV 
          + Alcohol
          + lot
          + dinner 
          + Total_hour 
          + upscale_classy
          ,family = cumulative(parallel = TRUE),data = train_test_split(data_china))

JP_model = vglm(OrderStar ~  BikeParking 
          + RestaurantsGoodForGroups 
          + WiFi 
          + garage 
          + street 
          + Total_hour 
          + upscale_classy,
          family = cumulative(parallel = TRUE),data = train_test_split(data_jpn))

AF_model = vglm(OrderStar ~  BikeParking 
          + RestaurantsReservations 
          + HasTV 
          + Alcohol
          + RestaurantsGoodForGroups 
          + WiFi 
          + lot
          + valet 
          + dinner 
          + Total_hour 
          + upscale_classy,
          family = cumulative(parallel = TRUE),data = train_test_split(data_AF))

general_model = vglm(OrderStar ~  BikeParking 
          + RestaurantsReservations 
          + Alcohol
          + WiFi 
          + garage 
          + street
          + lot
          + valet 
          + dinner 
          + Total_hour 
          + acceptable_noise 
          + upscale_classy,family = cumulative(parallel = TRUE),data = general_train)

# KN_model =vglm(OrderStar ~   HasTV 
#           + WiFi 
#           + Total_hour 
#           ,family = cumulative(parallel = TRUE),data = train_test_split(data_krn))




```







```{r}

#---------------------- Model prediction pie chart --------------------#
predict_model = function(category, BikeParking,RestaurantsGoodForGroups, WiFi,garage,valet, street,Total_hour,acceptable_noise,upscale_classy, HasTV, dinner, RestaurantsReservations, lot,Alcohol){
  columns = c('OrderStar','comment_star','BikeParking','RestaurantsGoodForGroups','WiFi','garage','valet', 'street_parking','Total_hour','acceptable_noise','upscale_classy','HasTV','dinner','RestaurantsReservations','lot','Alcohol')
  test_df = data.frame(matrix(nrow = 0, ncol = length(columns)))
  colnames(test_df) = columns
  

  new_row = list('BikeParking' = BikeParking,'RestaurantsGoodForGroups' = RestaurantsGoodForGroups,'WiFi' = WiFi,
            'garage' = garage,'valet' = valet, 'street_parking' = street,
            'Total_hour' = Total_hour,'acceptable_noise' = acceptable_noise,
            'upscale_classy' = upscale_classy,'HasTV' = HasTV, 'dinner' = dinner,
            'RestaurantsReservations' = RestaurantsReservations,
            'lot' = lot,'Alcohol' = Alcohol)
  
  
  test_df = rbind(test_df,new_row)
  test_df$BikeParking = as.factor(test_df$BikeParking)
  test_df$RestaurantsGoodForGroups = as.factor(test_df$RestaurantsGoodForGroups)
  test_df$WiFi = as.factor(test_df$WiFi)
  test_df$garage = as.factor(test_df$garage)
  test_df$valet = as.factor(test_df$valet)
  test_df$street = as.factor(test_df$street)
  test_df$acceptable_noise = as.factor(test_df$acceptable_noise)
  test_df$upscale_classy = as.factor(test_df$upscale_classy)
  test_df$HasTV = as.factor(test_df$HasTV)
  test_df$dinner = as.factor(test_df$dinner)
  test_df$RestaurantsReservations = as.factor(test_df$RestaurantsReservations)
  test_df$lot = as.factor(test_df$lot)
  test_df$Alcohol = as.factor(test_df$Alcohol)
  
  
  
  #remove columns based on different categories
  if (category == 'Chinese'){
    test_df = subset(test_df, select = c('BikeParking', 'HasTV','Alcohol','lot','dinner',
                                         'Total_hour','upscale_classy'))
    model = CN_model
  }
  else if(category == 'Japanese'){
    test_df = subset(test_df, select = c('BikeParking',
                                         'RestaurantsGoodForGroups','WiFi','garage',
                                         'street','Total_hour','upscale_classy'))
    model = JP_model
  }
  # else if(category == 'Korean'){
  #   
  # }
  else if (category == 'Asian Fusion'){
    test_df = subset(test_df, select = c('BikeParking',
                                     'RestaurantsGoodForGroups','WiFi','HasTV',
                                     'Alcohol','RestaurantsReservations',
                                     'lot','valet','dinner','Total_hour','upscale_classy'))
    model = AF_model
  }
  else{
    test_df = test_df
    model = general_model
  }
  

  pred <- predict(model,test_df,type = "response")
  pie.prop <- as.vector(pred)
  pie.labels <- c("1 star","2 star", "3 star", "4 star","5 star")
  pie.labels <- paste(pie.labels," ",round(pie.prop,2) , sep="")
  return(pie(pie.prop, pie.labels, col=brewer.pal(5, "RdYlGn")))
}



#--------------------- Model interpretation ---------------------#
model_intp = function(category, BikeParking,RestaurantsGoodForGroups, WiFi,garage,valet, street,Total_hour,acceptable_noise,upscale_classy, HasTV, dinner, RestaurantsReservations, lot, Alcohol){
  columns = c('OrderStar','comment_star','BikeParking','RestaurantsGoodForGroups','WiFi','garage','valet', 'street_parking','Total_hour','acceptable_noise','upscale_classy','HasTV','dinner','RestaurantsReservations','lot','Alcohol')
  test_df = data.frame(matrix(nrow = 0, ncol = length(columns)))
  colnames(test_df) = columns
  

  new_row = list('BikeParking' = BikeParking,'RestaurantsGoodForGroups' = RestaurantsGoodForGroups,'WiFi' = WiFi,
            'garage' = garage,'valet' = valet, 'street_parking' = street,
            'Total_hour' = Total_hour,'acceptable_noise' = acceptable_noise,
            'upscale_classy' = upscale_classy,'HasTV' = HasTV, 'dinner' = dinner,
            'RestaurantsReservations' = RestaurantsReservations,
            'lot' = lot,'Alcohol' = Alcohol)
  
  
  test_df = rbind(test_df,new_row)
  test_df$BikeParking = as.factor(test_df$BikeParking)
  test_df$RestaurantsGoodForGroups = as.factor(test_df$RestaurantsGoodForGroups)
  test_df$WiFi = as.factor(test_df$WiFi)
  test_df$garage = as.factor(test_df$garage)
  test_df$valet = as.factor(test_df$valet)
  test_df$street = as.factor(test_df$street)
  test_df$acceptable_noise = as.factor(test_df$acceptable_noise)
  test_df$upscale_classy = as.factor(test_df$upscale_classy)
  test_df$HasTV = as.factor(test_df$HasTV)
  test_df$dinner = as.factor(test_df$dinner)
  test_df$RestaurantsReservations = as.factor(test_df$RestaurantsReservations)
  test_df$lot = as.factor(test_df$lot)
  test_df$Alcohol = as.factor(test_df$Alcohol)
  
  
  
  #remove columns based on different categories
  if (category == 'Chinese'){
    test_df = subset(test_df, select = c('BikeParking', 'HasTV','Alcohol','lot','dinner',
                                         'Total_hour','upscale_classy'))
    model = CN_model
  }
  else if(category == 'Japanese'){
    test_df = subset(test_df, select = c('BikeParking',
                                         'RestaurantsGoodForGroups','WiFi','garage',
                                         'street','Total_hour','upscale_classy'))
    model = JP_model
  }
  # else if(category == 'Korean'){
  #   
  # }
  else if (category == 'Asian Fusion'){
    test_df = subset(test_df, select = c('BikeParking',
                                     'RestaurantsGoodForGroups','WiFi','HasTV',
                                     'Alcohol','RestaurantsReservations',
                                     'lot','valet','dinner','Total_hour','upscale_classy'))
    model = AF_model
  }
  else{
    test_df = test_df
    model = general_model
  }
  
  
  pred <- predict(model,test_df,type = "response")
  return(pred)
  
}

```






```{r}
ui = fluidPage(
  titlePanel('Your customer review and satisfication analysis'),
  column(2,
     wellPanel(
       titlePanel('Restaurant name'),
       selectInput('category', 'Select business category', choice = unique(CA_Asian_business_review$general_category)),
       uiOutput('business_name'))
  ),
  
  mainPanel(
    tabsetPanel(
      tabPanel('Word Cloud', 
       column(4,plotOutput('wordcloud_positive'),
        br(),
        br(),
        br(),), 
       column(4,plotOutput('wordcloud_neutral'),
        br(),
        br(),
        br(),),
       column(4,plotOutput('wordcloud_negative'),
        br(),
        br(),
        br(),),
       textOutput('wordCloud_instruction'),
        tags$head(br(),tags$style("#wordCloud_instruction{color: red;font-size: 13px;
        font-style: bold;
        }")),
      ),
      
    tabPanel('Text Frequency',
     textOutput('ngram_hint'),
      tags$head(tags$style("#ngram_hint{color: red;
     font-size: 15px;font-style: bold;}")),
      br(),
      br(),
     column(2,numericInput('n_result','Top N view', value = 1, min = 1, max = 100)),
     column(2, numericInput('n_gram','length of text', value = 1, min = 1, max = 10)),
     column(2, selectInput('sentiment','Choose a sentiment', choice = unique(CA_Asian_business_review$sentiment))),
     column(2, sliderInput('TF_font_size', label = 'font size', min =1, max = 50, value = 10)),
      column(2, sliderInput('TF_rotation', label = 'Rotate label', min =0, max = 180, value = 15)),
     plotOutput('n_gram')
    ),
    
    tabPanel('Text Importance', 
     textOutput('tfidf_hint'),
     tags$head(tags$style("#tfidf_hint{color: red;
     font-size: 15px;font-style: bold;}")),
      br(),
      br(),
     column(2,numericInput('TI_N_result','Top N view', value = 1, min = 1, max = 50)),
     column(2,numericInput('TI_n_gram','length of text', value = 1, min = 1, max = 10)),
     column(2,selectInput('TI_sentiment','Choose a sentiment', choice = unique(CA_Asian_business_review$sentiment))),
      column(2, sliderInput('TI_font_size', label = 'Font size', min =1, max = 50, value = 10)),
  column(2, sliderInput('TI_rotation', label = 'Rotate label', min =0, max = 180, value = 15)),
     plotOutput('text_importance')
    ),
    
    tabPanel('Parking map', includeHTML('parking.html')),
    tabPanel('Feature modeling',
      textOutput('modeling_instruction'),
      tags$head(tags$style("#modeling_instruction{color: blue;
       font-size: 15px;font-style: bold;}")),
      br(),
      br(),

      column(3, selectInput('wifi','WIFI', choices =list(0,1)),
             numericInput('total_hour','Total_opening_hour',value = 50,min = 1,max=168),
             selectInput('lot','Parking lot', choices = list(0,1)),
             ), 
      
      column(3, selectInput('valet','Valet Parking', choices = list(0,1)),
             selectInput('garage','Garage Parking', choices = list(0,1)),
             selectInput('street_park','Street Parking', choices = list(0,1)),
             ),
     
      column(3, selectInput('noise','Noise level', choices = list(0,1)),
             selectInput('upscale_classy','Upscale or Classy', choices = list(0,1)),
             selectInput('bike_park','Bike Parking', choices = list(0,1)),
             selectInput('alcohol','Alcohol', choices = list(0,1))
             ),

      column(3, selectInput('TV', 'Has TV', choices = list(0,1)),
             selectInput('dinner','Dinner provided', choices = list(0,1)),
             selectInput('good_for_group','Group friendly', choices = list(0,1)),
             selectInput('reservation','Reservation provided', choices = list(0,1))),
             
      
      fluidPage(
        column(6, plotOutput('modeling')),
        column(6,
                br(),
                br(),
                br(),
                br(),
                br(),
               htmlOutput('model_interpretation'),
               tags$head(tags$style("#model_interpretation{color: blue;
               font-size: 13px;font-style: bold;}"))
               )
        ),
        textOutput('modeling_hint'),
        tags$head(tags$style("#modeling_instruction{color: red;font-size: 13px;
        font-style: bold;
        }")),
      )
    )
  )
  
)


# ------------------ App virtualenv setup (Do not edit) ------------------- #
# PYTHON_DEPENDENCIES = c('pip','pandas', 'numpy','matplotlib','collections','sklearn','plotly','sys','warnings','tqdm','seaborn','nltk',)
# 
# virtualenv_dir = Sys.getenv('VIRTUALENV_NAME')
# python_path = Sys.getenv('PYTHON_PATH')
# 
# # Create virtual env and install dependencies
# reticulate::virtualenv_create(envname = virtualenv_dir, python = python_path)
# reticulate::virtualenv_install(virtualenv_dir, packages = PYTHON_DEPENDENCIES, ignore_installed=TRUE)
# reticulate::use_virtualenv(virtualenv_dir, required = T)


# ------------------ App server logic (Edit anything below) --------------- #
server = function(input, output){
  
  output$business_name = renderUI({
    if (input_provided(input$category)){
      cur_df = CA_Asian_business_review[CA_Asian_business_review['general_category']== input$category, ]
      selectInput('business_name','Select business name', choice = unique(cur_df$name))
    }
    else {
      selectInput('business_name','Select business name', choice = unique(CA_Asian_business_review$name))
    }
  })
  

  output$wordcloud_positive = renderPlot({
    cur_len = py$check_len('Positive',input$business_name)
    if (cur_len > 0){
      py$show_word_cloud('Positive',input$business_name)
    }
    
  })
  
  output$wordcloud_neutral = renderPlot({
    cur_len = py$check_len('Neutral',input$business_name)
    if (cur_len > 0){
      py$show_word_cloud('Neutral',input$business_name)
    }

  })
  
  output$wordcloud_negative = renderPlot({
    cur_len = py$check_len('Negative',input$business_name)
    if (cur_len > 0){
      py$show_word_cloud('Negative',input$business_name)
    }
  })
  
  output$n_gram = renderPlot({
    py$n_gram_plot(input$n_gram, input$business_name, 
                   input$n_result,input$sentiment, input$TF_font_size, input$TF_rotation)
  })
  
  output$text_importance = renderPlot({
    py$tfidf_viz( input$business_name, input$TI_sentiment , input$TI_n_gram, input$TI_N_result, input$TI_font_size, input$TI_rotation, input$category)
  })
  
  output$modeling = renderPlot({
    if(input_provided(input$category) == FALSE){
      category = 'other'
    }else{
      if (input$category == 'Chinese'){
        category ='Chinese'
      }
      else if (input$category == 'Japanese'){
        category ='Chinese'
            }
      else if (input$category == 'Korean'){
        category ='Korean'
      }
      else {
        category ='Asian Fusion'
      }
    }
    predict_model(category,input$bike_park,input$good_for_group,input$wifi,input$garage,input$valet, input$street_park,input$total_hour,input$noise,input$upscale_classy, input$TV, input$dinner, input$reservation, input$lot, input$alcohol)
  })
  

  
  
  #------------------ Instruction text ------------------#
  output$wordCloud_instruction = renderText({
    'Hint: the more a specific word appears in a source of textual data, the bigger and bolder it appears in the word cloud'
  })
  
  
  output$modeling_hint = renderText({
    'Hint: 0 means you do not have the feature, 1 means you want this feature'
  })
  
  
  output$modeling_instruction = renderText({
    'Instruction: This part is only related to category & features appeared in the page!!!'
  })
  
  
  output$ngram_hint = renderText({
    'Hint: the higher the count, the more frequent a word/text appears'
  })
  
  output$tfidf_hint = renderText({
    'Hint: the higher the TF-IDF score, the more important or relevant to term is'
  })
  
  
  output$model_interpretation = renderText({
    if(input_provided(input$category) == FALSE){
      category = 'other'
    }else{
      if (input$category == 'Chinese'){
        category ='Chinese'
      }
      else if (input$category == 'Japanese'){
        category ='Chinese'
            }
      else if (input$category == 'Korean'){
        category ='Korean'
      }
      else {
        category ='Asian Fusion'
      }
    }
    pred = model_intp(category,input$bike_park,input$good_for_group,input$wifi,input$garage,input$valet, input$street_park,input$total_hour,input$noise,input$upscale_classy, input$TV, input$dinner, input$reservation, input$lot, input$alcohol)
    str1 = paste0("The predicted probability of getting star 1 is: ", 100*round(pred[1],2), '%')
    str2 = paste0("The predicted probability of getting star 2 is: ", 100*round(pred[2],2), '%')
    str3 = paste0("The predicted probability of getting star 3 is: ", 100*round(pred[3],2), '%')
    str4 = paste0("The predicted probability of getting star 4 is: ", 100*round(pred[4],2), '%')
    str5 = paste0("The predicted probability of getting star 5 is: ", 100*round(pred[5],2), '%')
    HTML(paste(str1, str2, str3,str4, str5, sep = '<br/>'))
  })
  
  
}

shinyApp(ui, server)
```





















